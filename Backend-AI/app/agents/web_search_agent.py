from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Any, Optional
from loguru import logger
from contextvars import ContextVar
import json
from datetime import datetime, timezone


from langchain.tools import tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from app.integrations.gigachat_client import GigaChatClient
from app.integrations import duckduckgo_service
from app.config import settings


@dataclass
class WebSearchContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Web Search Agent"""
    user_id: int
    current_pet_name: str = ""
    current_pet_species: str = ""


_web_search_context: ContextVar[Optional[WebSearchContext]] = ContextVar(
    '_web_search_context',
    default=None
)


def _get_context() -> WebSearchContext:
    """Get the current web search context from ContextVar"""
    ctx = _web_search_context.get()
    if ctx is None:
        raise RuntimeError("WebSearch context not set. This should not happen.")
    return ctx


@tool
async def search_web(
    query: str,
    max_results: int = 5,
    recent_only: bool = False,
) -> str:
    """–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ DuckDuckGo.
    
    –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —Ñ–∞–∫—Ç—ã, –Ω–æ–≤–æ—Å—Ç–∏, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.
    –ê–≥–µ–Ω—Ç –°–ê–ú —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–∫—Ä–∞—Ç–∫–∏–π –∏ —Ç–æ—á–Ω—ã–π, 3-7 —Å–ª–æ–≤)
               –ü—Ä–∏–º–µ—Ä—ã: "–∫–æ—à–∫–∞ —á–∏—Ö–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω—ã –ª–µ—á–µ–Ω–∏–µ"
                        "–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∏–Ω–∏–∫–∞ –ú–æ—Å–∫–≤–∞ —Ä–µ–π—Ç–∏–Ω–≥"
                        "–∫–æ—Ä–º Royal Canin —Ü–µ–Ω–∞ –æ—Ç–∑—ã–≤—ã"
        max_results: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)
        recent_only: –ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü (–¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π)
    
    Returns:
        JSON string —Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
        {
          "query": str,
          "provider": "duckduckgo",
          "retrieved_at": ISO8601 timestamp,
          "results": [
              {
                "rank": int,
                "title": str,
                "url": str,
                "snippet": str
              }
          ]
        }
    """
    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo
        timelimit = "m" if recent_only else None
        
        results = await duckduckgo_service.search(
            query=query,
            max_results=max_results,
            timelimit=timelimit,
            region="ru-ru"
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        structured_result = {
            "query": query,
            "provider": "duckduckgo",
            "retrieved_at": datetime.now(timezone.utc).isoformat(),
            "results": []
        }
        
        for i, result in enumerate(results, 1):
            structured_result["results"].append({
                "rank": i,
                "title": result.get("title", ""),
                "url": result.get("href", ""),
                "snippet": result.get("body", "")
            })
        
        logger.info(
            f"Web search: query='{query}', recent_only={recent_only}, "
            f"found={len(results)} results"
        )
        
        return json.dumps(structured_result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Web search failed: {e}")
        error_result = {
            "query": query,
            "provider": "duckduckgo",
            "retrieved_at": datetime.now(timezone.utc).isoformat(),
            "error": str(e),
            "results": []
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)


@tool
async def fetch_webpage(url: str, max_length: int = 15000) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã.

    –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞:
    - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Å—ã–ª–∫—É
    - –ù—É–∂–Ω–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    - –ü–æ—Å–ª–µ –ø–æ–∏—Å–∫–∞ –Ω—É–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç—å—é

    Args:
        url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 15000 —Å–∏–º–≤–æ–ª–æ–≤)

    Returns:
        JSON string —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã:
        {
          "url": str,
          "title": str|null,
          "retrieved_at": ISO8601 timestamp,
          "content": str,
          "truncated": bool,
          "content_length": int
        }
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º title
        title = None
        if soup.title:
            title = soup.title.string
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(["script", "style", "nav", "header", "footer", "aside"]):
            element.decompose()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = soup.get_text()
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–µ–∑–∞—Ç—å
        original_length = len(text)
        truncated = original_length > max_length
        
        if truncated:
            text = text[:max_length]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        structured_result = {
            "url": url,
            "title": title,
            "retrieved_at": datetime.now(timezone.utc).isoformat(),
            "content": text,
            "truncated": truncated,
            "content_length": original_length
        }
        
        logger.info(
            f"Fetched webpage: url={url}, length={original_length}, "
            f"truncated={truncated}"
        )
        
        return json.dumps(structured_result, ensure_ascii=False, indent=2)
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to fetch {url}: {e}")
        error_result = {
            "url": url,
            "title": None,
            "retrieved_at": datetime.now(timezone.utc).isoformat(),
            "error": f"Network error: {str(e)}",
            "content": "",
            "truncated": False,
            "content_length": 0
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Error parsing {url}: {e}")
        error_result = {
            "url": url,
            "title": None,
            "retrieved_at": datetime.now(timezone.utc).isoformat(),
            "error": f"Parse error: {str(e)}",
            "content": "",
            "truncated": False,
            "content_length": 0
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2)


# ============================================================================
# WEB SEARCH AGENT
# ============================================================================

class WebSearchAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ DuckDuckGo
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
    –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ä–µ—à–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
    - –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    - –ü–µ—Ä–µ–¥–∞—Ç—å –≤ DocumentRAGAgent –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞
    """
    
    def __init__(self, llm=None):
        """
        Args:
            llm: LLM –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        self.llm = llm or GigaChatClient().llm
        
        # –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self.tools = [
            search_web,
            fetch_webpage
        ]
        
        logger.info("WebSearchAgent initialized with 2 tools (DuckDuckGo)")
    
    async def process(
        self,
        user_id: int,
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç (current_pet_name, current_pet_species)
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (–ù–ï –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç)
        """
        context = context or {}
        token = None
        
        try:
            # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            tool_context = WebSearchContext(
                user_id=user_id,
                current_pet_name=context.get("current_pet_name", ""),
                current_pet_species=context.get("current_pet_species", ""),
            )
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            token = _web_search_context.set(tool_context)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∏—Ç–æ–º—Ü–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            pet_info = ""
            if tool_context.current_pet_name:
                pet_info = f"\nüêæ –¢–µ–∫—É—â–∏–π –ø–∏—Ç–æ–º–µ—Ü: {tool_context.current_pet_name}"
                if tool_context.current_pet_species:
                    pet_info += f" ({tool_context.current_pet_species})"
            
            # System prompt
            system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É –∏ —Å–±–æ—Ä—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤ –¥–æ–º–∞—à–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ID: {user_id}{pet_info}

**–¢–≤–æ–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–≤—Å–µ–≥–æ 2):**

1. **search_web(query, max_results, recent_only)** - –ü–æ–∏—Å–∫ –≤ DuckDuckGo
   - –¢—ã –°–ê–ú —Ñ–æ—Ä–º–∏—Ä—É–µ—à—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
   - –î–µ–ª–∞–π –∑–∞–ø—Ä–æ—Å—ã —Ç–æ—á–Ω—ã–º–∏ –∏ –∫—Ä–∞—Ç–∫–∏–º–∏ (3-7 —Å–ª–æ–≤)
   - –ò—Å–ø–æ–ª—å–∑—É–π —Ä—É—Å—Å–∫–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
   - –î–ª—è –ø–∏—Ç–æ–º—Ü–µ–≤ –¥–æ–±–∞–≤–ª—è–π –≤–∏–¥ –≤ –∑–∞–ø—Ä–æ—Å

2. **fetch_webpage(url, max_length=15000)** - –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
   - –ó–∞–≥—Ä—É–∂–∞–µ—Ç –í–ï–°–¨ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–æ 15000 —Å–∏–º–≤–æ–ª–æ–≤)
   - –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è 2-3 –°–ê–ú–´–• –†–ï–õ–ï–í–ê–ù–¢–ù–´–• —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
   - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã

**–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å:**

–®–∞–≥ 1: –í—ã–ø–æ–ª–Ω–∏ search_web –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
–®–∞–≥ 2: –í—ã–±–µ—Ä–∏ 2-3 –°–ê–ú–´–• –†–ï–õ–ï–í–ê–ù–¢–ù–´–• —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏ –≤—ã–∑–æ–≤–∏ fetch_webpage –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –Ω–∏—Ö
–®–∞–≥ 3: –í–µ—Ä–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ë–ï–ó –∞–Ω–∞–ª–∏–∑–∞ - —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)

**–§–æ—Ä–º–∞—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞:**
–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–π –í–ê–õ–ò–î–ù–´–ô JSON –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–π \\n –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:
{{{{
  "search_results": [
    {{{{
      "rank": 1,
      "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
      "url": "https://...",
      "snippet": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –ø–æ–∏—Å–∫–∞"
    }}}}
  ],
  "loaded_pages": [
    {{{{
      "url": "https://...",
      "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
      "content": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ fetch_webpage)"
    }}}}
  ],
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö: —á—Ç–æ –Ω–∞—à–µ–ª –∏ –∫–∞–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∑–∞–≥—Ä—É–∑–∏–ª"
}}}}

**–í–ê–ñ–ù–û:**
- –í "search_results" –≤–∫–ª—é—á–∞–π –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (rank, title, url, snippet)
- –í "loaded_pages" –≤–∫–ª—é—á–∞–π –ü–û–õ–ù–´–ô —Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è 2-3 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (—Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã –∑–∞–≥—Ä—É–∑–∏–ª —á–µ—Ä–µ–∑ fetch_webpage)
- –í "summary" –Ω–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ: —á—Ç–æ –∏—Å–∫–∞–ª, —Å–∫–æ–ª—å–∫–æ –Ω–∞—à–µ–ª, –∫–∞–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∑–∞–≥—Ä—É–∑–∏–ª
- –ù–ï –¥–µ–ª–∞–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
- –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ù–ê–ô–¢–ò –∏ –ó–ê–ì–†–£–ó–ò–¢–¨ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

**–ü—Ä–∞–≤–∏–ª–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤:**

  **–•–æ—Ä–æ—à–∏–µ –∑–∞–ø—Ä–æ—Å—ã:**
- "–∫–æ—à–∫–∞ —á–∏—Ö–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω—ã –ª–µ—á–µ–Ω–∏–µ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä"
- "—Å–æ–±–∞–∫–∞ –ø–æ–Ω–æ—Å —á—Ç–æ –¥–µ–ª–∞—Ç—å"
- "–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∏–Ω–∏–∫–∞ –ú–æ—Å–∫–≤–∞ —Ä–µ–π—Ç–∏–Ω–≥"
- "–∫–æ—Ä–º Royal Canin —Å–æ—Å—Ç–∞–≤ –æ—Ç–∑—ã–≤—ã"
- "–ø—Ä–∏–≤–∏–≤–∫–∞ –æ—Ç –±–µ—à–µ–Ω—Å—Ç–≤–∞ –∫–æ—à–∫–∞ —Ü–µ–Ω–∞"

  **–ü–ª–æ—Ö–∏–µ –∑–∞–ø—Ä–æ—Å—ã:**
- "—á—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –∫–æ—à–∫–∞ —á–∏—Ö–∞–µ—Ç" (—Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ)
- "cat sneezing" (–¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–π —Ä—É—Å—Å–∫–∏–π)
- "—á–∏—Ö–∞–Ω–∏–µ" (—Å–ª–∏—à–∫–æ–º –æ–±—â–æ, –¥–æ–±–∞–≤—å –∫–æ–Ω—Ç–µ–∫—Å—Ç)

**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤:**

1. **–í–æ–ø—Ä–æ—Å—ã –æ –∑–¥–æ—Ä–æ–≤—å–µ –ø–∏—Ç–æ–º—Ü–µ–≤:**
   - –î–æ–±–∞–≤–ª—è–π: –≤–∏–¥ –∂–∏–≤–æ—Ç–Ω–æ–≥–æ + —Å–∏–º–ø—Ç–æ–º + "–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä"
   - –ü—Ä–∏–º–µ—Ä: "—Å–æ–±–∞–∫–∞ —Ä–≤–æ—Ç–∞ –ø–æ–Ω–æ—Å –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä –ª–µ—á–µ–Ω–∏–µ"

2. **–ü–æ–∏—Å–∫ –∫–ª–∏–Ω–∏–∫:**
   - –î–æ–±–∞–≤–ª—è–π: "–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∏–Ω–∏–∫–∞" + –≥–æ—Ä–æ–¥ + "–æ—Ç–∑—ã–≤—ã —Ä–µ–π—Ç–∏–Ω–≥"
   - –ü—Ä–∏–º–µ—Ä: "–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∏–Ω–∏–∫–∞ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ –æ—Ç–∑—ã–≤—ã"

3. **–ù–æ–≤–æ—Å—Ç–∏ (recent_only=True):**
   - –î–æ–±–∞–≤–ª—è–π: —Ç–µ–º–∞ + "–Ω–æ–≤–æ—Å—Ç–∏"
   - –ü—Ä–∏–º–µ—Ä: "–∫–æ—Ä–º –¥–ª—è –∫–æ—à–µ–∫ –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç–∑—ã–≤"

4. **–¶–µ–Ω—ã –∏ –ø–æ–∫—É–ø–∫–∏:**
   - –î–æ–±–∞–≤–ª—è–π: —Ç–æ–≤–∞—Ä + "—Ü–µ–Ω–∞ –æ—Ç–∑—ã–≤—ã –≥–¥–µ –∫—É–ø–∏—Ç—å"
   - –ü—Ä–∏–º–µ—Ä: "Royal Canin –¥–ª—è –∫–æ—à–µ–∫ —Ü–µ–Ω–∞ –æ—Ç–∑—ã–≤—ã"

**–ö–æ–≥–¥–∞ –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫:**
- –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã (–º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–∞–º)
- –õ–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –í–æ–ø—Ä–æ—Å—ã –æ –ø–∏—Ç–æ–º—Ü–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã)

**–ö–æ–≥–¥–∞ –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –ø–æ–∏—Å–∫:**
- –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è)
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
- –¶–µ–Ω—ã, —Ç–æ–≤–∞—Ä—ã, —É—Å–ª—É–≥–∏
- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Ñ–∞–∫—Ç—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø—Ä–æ—Å–∏—Ç –ø–æ–∏—Å–∫–∞—Ç—å

**–ü—Ä–∏–º–µ—Ä —Ö–æ—Ä–æ—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞:**
{{{{
  "search_results": [
    {{{{"rank": 1, "title": "–£—Ö–æ–¥ –∑–∞ –∫–æ—Ç–æ–º", "url": "https://example.com/1", "snippet": "10 —Å–æ–≤–µ—Ç–æ–≤..."}}}},
    {{{{"rank": 2, "title": "–°—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–æ—Ç–æ–≤", "url": "https://example.com/2", "snippet": "–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞..."}}}}
  ],
  "loaded_pages": [
    {{{{"url": "https://example.com/1", "title": "–£—Ö–æ–¥ –∑–∞ –∫–æ—Ç–æ–º", "content": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ —É—Ö–æ–¥ –∑–∞ –∫–æ—Ç–æ–º..."}}}},
    {{{{"url": "https://example.com/2", "title": "–°—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–æ—Ç–æ–≤", "content": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ —Å—Ä–µ–¥—Å—Ç–≤–∞..."}}}}
  ],
  "summary": "–ù–∞–π–¥–µ–Ω–æ 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É '—Å—Ä–µ–¥—Å—Ç–≤–∞ —É—Ö–æ–¥–∞ –∑–∞ –∫–æ—Ç–æ–º'. –ó–∞–≥—Ä—É–∂–µ–Ω—ã 2 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏."
}}}}

**–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø–æ–ª—É—á–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ RAG –∏–ª–∏ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞"""
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])
            
            agent = create_tool_calling_agent(self.llm, self.tools, prompt)
            agent_executor = AgentExecutor(
                agent=agent,
                tools=self.tools,
                verbose=settings.DEBUG,
                handle_parsing_errors=True,
                max_iterations=10,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ—Å–ª–µ –ø–æ–∏—Å–∫–∞
            )
            
            result = await agent_executor.ainvoke({"input": user_message})
            return result.get("output", '{"error": "No output from agent"}')
            
        except Exception as e:
            logger.exception(f"WebSearchAgent error for user {user_id}")
            error_result = {
                "error": str(e),
                "user_id": user_id,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            return json.dumps(error_result, ensure_ascii=False)
        finally:
            if token is not None:
                _web_search_context.reset(token)