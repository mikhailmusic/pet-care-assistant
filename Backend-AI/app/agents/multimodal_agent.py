# app/agents/multimodal_agent.py

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Any, List, Optional, Literal, BinaryIO
from datetime import datetime, timezone
from loguru import logger
from contextvars import ContextVar
import json
import io
import base64

from langchain.tools import tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from app.integrations.gigachat_client import gigachat_client
from app.integrations import salutespeech_service
from app.integrations.minio_service import MinioService
from app.integrations import minio_service as MinioServiceDep
from app.config import settings


@dataclass
class MultimodalContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Multimodal Agent"""
    user_id: int
    uploaded_files: List[Dict[str, Any]]


_multimodal_context: ContextVar[Optional[MultimodalContext]] = ContextVar(
    '_multimodal_context',
    default=None
)

_minio_service: ContextVar[Optional[MinioService]] = ContextVar('_minio_service', default=None)



def _get_context() -> MultimodalContext:
    """Get the current context from ContextVar"""
    ctx = _multimodal_context.get()
    if ctx is None:
        raise RuntimeError("Multimodal context not set.")
    return ctx


def _get_minio_service() -> MinioService:
    service = _minio_service.get()
    if service is None:
        raise RuntimeError("Minio service not set.")
    return service


async def _get_file_from_ref(file_ref: Optional[str]) -> tuple[BinaryIO, str, str]:
    """
    Returns: (file_object(BytesIO), filename, mime_type)
    """
    ctx = _get_context()
    minio_service = _get_minio_service()

    logger.debug(f"_get_file_from_ref called with file_ref={file_ref}, uploaded_files count={len(ctx.uploaded_files)}")

    if not file_ref:
        # –°–ª—É—á–∞–π 1: file_ref –Ω–µ —É–∫–∞–∑–∞–Ω - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª
        if not ctx.uploaded_files:
            raise ValueError("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –£–∫–∞–∂–∏ file_ref –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª.")
        file_info = ctx.uploaded_files[0]
        object_name = file_info.get("object_name") or file_info.get("file_id")
        filename = file_info.get("filename") or file_info.get("file_name", "unknown")
        mime_type = file_info.get("mime_type", "application/octet-stream")
    else:
        # –°–ª—É—á–∞–π 2: file_ref —É–∫–∞–∑–∞–Ω - –∏—â–µ–º —Ñ–∞–π–ª –ø–æ object_name –∏–ª–∏ file_id
        file_info = next(
            (f for f in ctx.uploaded_files
             if f.get("object_name") == file_ref or f.get("file_id") == file_ref
             or f.get("filename") == file_ref or f.get("file_name") == file_ref),
            None
        )
        if file_info:
            # –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –≤ uploaded_files - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ object_name
            object_name = file_info.get("object_name") or file_info.get("file_id")
            filename = file_info.get("filename") or file_info.get("file_name", "unknown")
            mime_type = file_info.get("mime_type", "application/octet-stream")
        else:
            # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ uploaded_files - –∏—Å–ø–æ–ª—å–∑—É–µ–º file_ref –∫–∞–∫ –µ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–Ω—ã–π –ø—É—Ç—å)
            object_name = file_ref
            filename = file_ref.split("/")[-1] if "/" in file_ref else file_ref
            mime_type = "application/octet-stream"

    if not object_name:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å object_name —Ñ–∞–π–ª–∞")

    # –ï—Å–ª–∏ MIME-—Ç–∏–ø –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    if mime_type == "application/octet-stream":
        ext = filename.lower().rsplit('.', 1)[-1] if '.' in filename else ""
        mime_map = {
            'jpg': 'image/jpeg', 'jpeg': 'image/jpeg',
            'png': 'image/png', 'gif': 'image/gif',
            'bmp': 'image/bmp', 'webp': 'image/webp',
            'mp4': 'video/mp4', 'avi': 'video/x-msvideo',
            'mov': 'video/quicktime', 'mkv': 'video/x-matroska',
            'mp3': 'audio/mpeg', 'wav': 'audio/wav',
            'ogg': 'audio/ogg', 'flac': 'audio/flac',
        }
        mime_type = mime_map.get(ext, "application/octet-stream")

    logger.info(f"Attempting to download file with object_name={object_name}")
    file_object = await minio_service.download_file(object_name)
    if file_object is None:
        raise ValueError(f"–§–∞–π–ª {object_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
    file_object.seek(0)

    size = len(file_object.getbuffer())
    logger.info(f"Loaded file: {filename} ({size} bytes), mime_type={mime_type}, object_name={object_name}")

    return file_object, filename, mime_type


# ============================================================================
# TOOLS
# ============================================================================

@tool
async def analyze_image(
    file_ref: Optional[str] = None,
    prompt: str = "–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–∞ –ø–∏—Ç–æ–º—Ü–∞.",
    temperature: float = 0.2,
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ GigaChat Vision.
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è:
    - –ê–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ –ø–∏—Ç–æ–º—Ü–∞ (–≤–Ω–µ—à–Ω–∏–π –≤–∏–¥, —Å–æ—Å—Ç–æ—è–Ω–∏–µ)
    - –û—Ü–µ–Ω–∫–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤ –ø–æ —Ñ–æ—Ç–æ (—Å—ã–ø—å, —Ä–∞–Ω—ã, –∏–∑–º–µ–Ω–µ–Ω–∏—è)
    - –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥—ã
    - –ê–Ω–∞–ª–∏–∑–∞ —É—Å–ª–æ–≤–∏–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
    
    Args:
        file_ref: –°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª (object_name). –ï—Å–ª–∏ None - –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å/–Ω–∞–π—Ç–∏)
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-2.0)
    
    Returns:
        JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞:
        {
          "analyzed_at": ISO8601,
          "filename": str,
          "prompt": str,
          "analysis": str (—Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç GigaChat Vision),
          "file_ref": str
        }
    """
    try:
        ctx = _get_context()

        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª —Å MIME-—Ç–∏–ø–æ–º
        file_object, filename, mime_type = await _get_file_from_ref(file_ref)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GigaChat Vision
        analysis = await gigachat_client.vision_analysis(
            file=file_object,
            filename=filename,
            prompt=prompt,
            temperature=temperature,
            mime_type=mime_type
        )
        
        result = {
            "analyzed_at": datetime.now(timezone.utc).isoformat(),
            "filename": filename,
            "prompt": prompt,
            "analysis": analysis,
            "file_ref": file_ref or "auto_selected"
        }
        
        logger.info(f"Image analyzed: {filename}")
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Failed to analyze image: {e}")
        return json.dumps({
            "error": str(e),
            "filename": filename if 'filename' in locals() else "unknown"
        }, ensure_ascii=False)


@tool
async def ocr_image(
    file_ref: Optional[str] = None,
    mode: Literal["plain", "structured"] = "structured",
) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (OCR).
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è:
    - –ß—Ç–µ–Ω–∏—è —ç—Ç–∏–∫–µ—Ç–æ–∫ –∫–æ—Ä–º–æ–≤
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–ø—Ä–∞–≤–æ–∫
    - –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—Ü–µ–ø—Ç–æ–≤
    - –ß—Ç–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤
    
    Args:
        file_ref: –°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª. –ï—Å–ª–∏ None - –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π
        mode: –†–µ–∂–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:
              - "plain": –ø—Ä–æ—Å—Ç–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç
              - "structured": –ø—ã—Ç–∞–µ—Ç—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏)
    
    Returns:
        JSON —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º:
        {
          "analyzed_at": ISO8601,
          "filename": str,
          "mode": str,
          "text": str (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç),
          "structured_data": dict|null (–µ—Å–ª–∏ mode="structured"),
          "file_ref": str
        }
    """
    try:
        ctx = _get_context()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        file_object, filename, mime_type = await _get_file_from_ref(file_ref)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if mode == "plain":
            prompt = "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
        else:  # structured
            prompt = """–ò–∑–≤–ª–µ–∫–∏ —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –µ–≥–æ.
            
–ï—Å–ª–∏ —ç—Ç–æ —ç—Ç–∏–∫–µ—Ç–∫–∞ –∫–æ—Ä–º–∞:
- –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å
- –°–æ—Å—Ç–∞–≤ (—Å–ø–∏—Å–æ–∫ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤)
- –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–±–µ–ª–∫–∏, –∂–∏—Ä—ã, –∫–ª–µ—Ç—á–∞—Ç–∫–∞)
- –ö–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å
- –î–∞—Ç–∞ –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è/—Å—Ä–æ–∫ –≥–æ–¥–Ω–æ—Å—Ç–∏

–ï—Å–ª–∏ —ç—Ç–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç:
- –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
- –î–∞—Ç–∞
- –î–∏–∞–≥–Ω–æ–∑/–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–µ—Ä–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏."""
        
        # OCR —á–µ—Ä–µ–∑ GigaChat Vision
        ocr_result = await gigachat_client.vision_analysis(
            file=file_object,
            filename=filename,
            prompt=prompt,
            temperature=0.1  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        )
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –µ—Å–ª–∏ structured mode
        structured_data = None
        if mode == "structured":
            try:
                # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
                import re
                json_match = re.search(r'\{.*\}', ocr_result, re.DOTALL)
                if json_match:
                    structured_data = json.loads(json_match.group(0))
            except:
                logger.warning("Failed to parse structured OCR result as JSON")
        
        result = {
            "analyzed_at": datetime.now(timezone.utc).isoformat(),
            "filename": filename,
            "mode": mode,
            "text": ocr_result,
            "structured_data": structured_data,
            "file_ref": file_ref or "auto_selected"
        }
        
        logger.info(f"OCR completed: {filename}, mode={mode}")
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Failed to OCR image: {e}")
        return json.dumps({
            "error": str(e),
            "filename": filename if 'filename' in locals() else "unknown"
        }, ensure_ascii=False)


@tool
async def transcribe_audio(
    file_ref: Optional[str] = None,
    audio_format_hint: str = "audio/x-pcm;bit=16;rate=16000",
) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ SaluteSpeech STT.
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è:
    - –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ (–ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ)
    - –°–æ–∑–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∞
    
    Args:
        file_ref: –°—Å—ã–ª–∫–∞ –Ω–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª. –ï—Å–ª–∏ None - –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π
        audio_format_hint: –§–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ (–¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
                          –ü—Ä–∏–º–µ—Ä—ã: "audio/x-pcm;bit=16;rate=16000"
                                   "audio/wav"
    
    Returns:
        JSON —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π:
        {
          "transcribed_at": ISO8601,
          "filename": str,
          "audio_format": str,
          "text": str (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç),
          "duration_seconds": float|null,
          "file_ref": str
        }
    """
    try:
        ctx = _get_context()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        file_object, filename, mime_type = await _get_file_from_ref(file_ref)
        audio_data = file_object.read()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞
        # –ü–∞—Ä—Å–∏–º audio/x-pcm;bit=16;rate=16000
        sample_rate = 16000
        bit_depth = 16
        
        if "rate=" in audio_format_hint:
            import re
            rate_match = re.search(r'rate=(\d+)', audio_format_hint)
            if rate_match:
                sample_rate = int(rate_match.group(1))
        
        if "bit=" in audio_format_hint:
            import re
            bit_match = re.search(r'bit=(\d+)', audio_format_hint)
            if bit_match:
                bit_depth = int(bit_match.group(1))
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ SaluteSpeech
        transcribed_text = await salutespeech_service.speech_to_text(
            audio_data=audio_data,
            sample_rate=sample_rate,
            bit_depth=bit_depth
        )
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = None
        try:
            # –î–ª—è PCM: duration = bytes / (sample_rate * channels * bytes_per_sample)
            bytes_per_sample = bit_depth // 8
            channels = 1  # –ú–æ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            duration = len(audio_data) / (sample_rate * channels * bytes_per_sample)
        except:
            pass
        
        result = {
            "transcribed_at": datetime.now(timezone.utc).isoformat(),
            "filename": filename,
            "audio_format": audio_format_hint,
            "text": transcribed_text,
            "duration_seconds": round(duration, 2) if duration else None,
            "file_ref": file_ref or "auto_selected"
        }
        
        logger.info(f"Audio transcribed: {filename}, length={len(transcribed_text)} chars")
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Failed to transcribe audio: {e}")
        return json.dumps({
            "error": str(e),
            "filename": filename if 'filename' in locals() else "unknown"
        }, ensure_ascii=False)


@tool
async def analyze_video(
    file_ref: Optional[str] = None,
    prompt: str = "–û–ø–∏—à–∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ/—Å–∏–º–ø—Ç–æ–º—ã –Ω–∞ –≤–∏–¥–µ–æ. –û—Ç–¥–µ–ª—å–Ω–æ: —á—Ç–æ –Ω–∞—Å—Ç–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –∏ –∫–∞–∫–∏–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏.",
    frame_count: int = 10,
    transcribe: bool = True,
) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ + –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Vision).
    
    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è:
    - –ê–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–∏—Ç–æ–º—Ü–∞ –Ω–∞ –≤–∏–¥–µ–æ
    - –û—Ü–µ–Ω–∫–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤ –≤ –¥–∏–Ω–∞–º–∏–∫–µ
    - –ê–Ω–∞–ª–∏–∑–∞ –ø–æ—Ö–æ–¥–∫–∏, –¥–≤–∏–∂–µ–Ω–∏–π
    - –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∏—Ç–æ–º—Ü–∞
    
    Args:
        file_ref: –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ —Ñ–∞–π–ª. –ï—Å–ª–∏ None - –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π
        prompt: –ß—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –≤–∏–¥–µ–æ
        frame_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        transcribe: –ò–∑–≤–ª–µ—á—å –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
    
    Returns:
        JSON —Å –∞–Ω–∞–ª–∏–∑–æ–º –≤–∏–¥–µ–æ:
        {
          "analyzed_at": ISO8601,
          "filename": str,
          "prompt": str,
          "frame_count": int,
          "video_analysis": str (–∞–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–æ–≤),
          "audio_transcription": str|null (–µ—Å–ª–∏ transcribe=True),
          "frames_analyzed": [
            {"frame_number": int, "timestamp_sec": float}
          ],
          "file_ref": str
        }
    """
    try:
        ctx = _get_context()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        file_object, filename, mime_type = await _get_file_from_ref(file_ref)
        video_data = file_object.read()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        import tempfile
        import cv2
        
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
            temp_video.write(video_data)
            temp_video_path = temp_video.name
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã —á–µ—Ä–µ–∑ OpenCV
            cap = cv2.VideoCapture(temp_video_path)
            
            if not cap.isOpened():
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ —Ñ–∞–π–ª")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ –æ –≤–∏–¥–µ–æ
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –∫–∞–¥—Ä—ã –∏–∑–≤–ª–µ–∫–∞—Ç—å (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ –≤–∏–¥–µ–æ)
            frame_count = max(1, frame_count)
            if total_frames <= 0:
                frame_indices = [0]
            else:
                step = max(1, total_frames // frame_count)
                frame_indices = [min(total_frames - 1, i * step) for i in range(frame_count)]
                frame_indices = sorted(set(frame_indices))            
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
            extracted_frames = []
            frames_data = []
            
            for idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                
                if ret:
                    _, buffer = cv2.imencode('.jpg', frame)
                    frame_bytes = io.BytesIO(buffer.tobytes())
                    
                    timestamp = idx / fps if fps > 0 else 0
                    
                    extracted_frames.append({
                        "frame_number": idx,
                        "timestamp_sec": round(timestamp, 2)
                    })
                    frames_data.append((frame_bytes, f"frame_{idx}.jpg", "image/jpeg"))
            
            cap.release()
            
            logger.info(f"Extracted {len(frames_data)} frames from video: {filename}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã —á–µ—Ä–µ–∑ GigaChat Vision (multiple images)
            analysis_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ü–û–î–†–û–ë–ù–û —ç—Ç–∏ {len(frames_data)} –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ.

{prompt}

–í–∏–¥–µ–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é {duration:.1f} —Å–µ–∫. –ö–∞–¥—Ä—ã –≤–∑—è—Ç—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç–º–µ—Ç–∫–∞—Ö:
{chr(10).join([f"‚Ä¢ –ö–∞–¥—Ä {i+1}: {extracted_frames[i]['timestamp_sec']:.1f} —Å–µ–∫" for i in range(len(extracted_frames))])}

–í–ê–ñ–ù–û:
1. –û–ø–∏—à–∏ –ö–ê–ñ–î–´–ô –∫–∞–¥—Ä –æ—Ç–¥–µ–ª—å–Ω–æ - —á—Ç–æ –Ω–∞ –Ω—ë–º –≤–∏–¥–Ω–æ
2. –£–∫–∞–∂–∏ —á—Ç–æ –ú–ï–ù–Ø–ï–¢–°–Ø –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ (–¥–≤–∏–∂–µ–Ω–∏—è, –¥–µ–π—Å—Ç–≤–∏—è, –æ–±—ä–µ–∫—Ç—ã)
3. –û–ø–∏—à–∏ –æ–±—â—É—é –¥–∏–Ω–∞–º–∏–∫—É –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ —Å–æ–±—ã—Ç–∏–π
4. –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –¥–µ—Ç–∞–ª–∏: –ª—é–¥–µ–π, –æ–±—ä–µ–∫—Ç—ã, —Ç–µ–∫—Å—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
5. –ï—Å–ª–∏ –≤–∏–¥–Ω–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è/—ç–∫—Ä–∞–Ω - –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–ª–∞–π–¥–æ–≤

–î–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ."""
            
            video_analysis = await gigachat_client.vision_analysis_multiple(
                files=frames_data,
                prompt=analysis_prompt,
                temperature=0.5
            )
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            audio_transcription = None
            if transcribe:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ ffmpeg
                    import subprocess
                    import shutil

                    ffmpeg_path = None

                    try:
                        import imageio_ffmpeg
                        ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
                        logger.info(f"Using imageio-ffmpeg: {ffmpeg_path}")
                    except ImportError:
                        logger.debug("imageio-ffmpeg not installed, trying system ffmpeg")

                    # –ï—Å–ª–∏ imageio-ffmpeg –Ω–µ—Ç, –∏—â–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π ffmpeg
                    if not ffmpeg_path:
                        ffmpeg_path = shutil.which('ffmpeg')
                        if ffmpeg_path:
                            logger.info(f"Using system ffmpeg: {ffmpeg_path}")

                    if not ffmpeg_path:
                        logger.warning("ffmpeg not found in PATH and imageio-ffmpeg not installed")
                        audio_transcription = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: ffmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
                    else:
                        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
                            temp_audio_path = temp_audio.name

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PCM WAV 16kHz mono
                        result = subprocess.run([
                            ffmpeg_path, '-i', temp_video_path,
                            '-vn',  # –ë–µ–∑ –≤–∏–¥–µ–æ
                            '-acodec', 'pcm_s16le',  # PCM 16-bit
                            '-ar', '16000',  # 16kHz
                            '-ac', '1',  # –ú–æ–Ω–æ
                            temp_audio_path,
                            '-y'  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å
                        ], capture_output=True, text=True)

                        if result.returncode != 0:
                            logger.warning(f"ffmpeg failed: {result.stderr}")
                            audio_transcription = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ (–≤–æ–∑–º–æ–∂–Ω–æ, –≤–∏–¥–µ–æ –±–µ–∑ –∑–≤—É–∫–∞)."
                        else:
                            # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ
                            with open(temp_audio_path, 'rb') as f:
                                audio_data = f.read()

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                            if len(audio_data) < 100:
                                logger.warning("Audio file too small, video might have no audio track")
                                audio_transcription = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: –≤ –≤–∏–¥–µ–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∞."
                            else:
                                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
                                audio_transcription = await salutespeech_service.speech_to_text(
                                    audio_data=audio_data,
                                    sample_rate=16000,
                                    bit_depth=16
                                )

                                logger.info(f"Video audio transcribed: {len(audio_transcription)} chars")

                            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª
                            import os
                            try:
                                os.unlink(temp_audio_path)
                            except:
                                pass

                except FileNotFoundError as e:
                    logger.warning(f"ffmpeg not found: {e}")
                    audio_transcription = "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: ffmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install imageio-ffmpeg"
                except Exception as e:
                    logger.warning(f"Failed to transcribe video audio: {e}")
                    audio_transcription = f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {str(e)}"
            
            result = {
                "analyzed_at": datetime.now(timezone.utc).isoformat(),
                "filename": filename,
                "prompt": prompt,
                "frame_count": len(extracted_frames),
                "video_duration_sec": round(duration, 2),
                "video_analysis": video_analysis,
                "audio_transcription": audio_transcription,
                "frames_analyzed": extracted_frames,
                "file_ref": file_ref or "auto_selected"
            }
            
            logger.info(f"Video analyzed: {filename}, {len(extracted_frames)} frames")
            return json.dumps(result, ensure_ascii=False, indent=2)
            
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –≤–∏–¥–µ–æ —Ñ–∞–π–ª
            import os
            os.unlink(temp_video_path)
        
    except Exception as e:
        logger.error(f"Failed to analyze video: {e}")
        return json.dumps({
            "error": str(e),
            "filename": filename if 'filename' in locals() else "unknown"
        }, ensure_ascii=False)


# ============================================================================
# MULTIMODAL ANALYSIS AGENT
# ============================================================================

class MultimodalAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ)
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (GigaChat Vision)
    - OCR —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    - –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ (SaluteSpeech STT)
    - –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ (–∫–∞–¥—Ä—ã + –∞—É–¥–∏–æ)
    """
    
    def __init__(self, minio_service: MinioService, llm=None):
        """
        Args:
            minio_service: –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏
            llm: LLM –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        from app.integrations.gigachat_client import GigaChatClient
        
        self.minio_service = minio_service or MinioServiceDep
        self.llm = llm or GigaChatClient().llm
        
        # –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self.tools = [
            analyze_image,
            ocr_image,
            transcribe_audio,
            analyze_video,
        ]
        
        logger.info("MultimodalAgent initialized with 4 tools")
    
    async def process(
        self,
        user_id: int,
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        context = context or {}
        token = None
        minio_token = None
        
        try:
            tool_context = MultimodalContext(
                user_id=user_id,
                uploaded_files=context.get("uploaded_files", [])
            )
            
            ctx_token = _multimodal_context.set(tool_context)
            minio_token = _minio_service.set(self.minio_service) 
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            files_info = ""
            if tool_context.uploaded_files:
                files_list = [
                    f"{f.get('filename', 'unknown')} ({f.get('file_type', 'unknown')})"
                    for f in tool_context.uploaded_files[:3]
                ]
                files_info = f"\nüìé –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {', '.join(files_list)}"
                if len(tool_context.uploaded_files) > 3:
                    files_info += f" –∏ –µ—â—ë {len(tool_context.uploaded_files) - 3}"
            
            # System prompt
            system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –¥–ª—è –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤ –¥–æ–º–∞—à–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ID: {user_id}{files_info}

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (4):**

1. **analyze_image** - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ GigaChat Vision
   –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è: —Ñ–æ—Ç–æ –ø–∏—Ç–æ–º—Ü–∞, —Å–∏–º–ø—Ç–æ–º–æ–≤, —É—Å–ª–æ–≤–∏–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥—ã
   
2. **ocr_image** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (OCR)
   –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è: —ç—Ç–∏–∫–µ—Ç–æ–∫ –∫–æ—Ä–º–æ–≤, —Å–ø—Ä–∞–≤–æ–∫, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤, —Ä–µ—Ü–µ–ø—Ç–æ–≤
   –†–µ–∂–∏–º—ã: "plain" (–ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç) –∏–ª–∏ "structured" (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
   
3. **transcribe_audio** - –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç
   –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è: –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
   
4. **analyze_video** - –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ (–∫–∞–¥—Ä—ã + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∞—É–¥–∏–æ)
   –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è: –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–∏—Ç–æ–º—Ü–∞, —Å–∏–º–ø—Ç–æ–º–æ–≤ –≤ –¥–∏–Ω–∞–º–∏–∫–µ, –ø–æ—Ö–æ–¥–∫–∏
   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: frame_count (—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤), transcribe (–∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ)

**file_ref:**
- –ù–ï –£–ö–ê–ó–´–í–ê–ô file_ref –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –û–î–ò–ù —Ñ–∞–π–ª - –æ–Ω –≤–æ–∑—å–º–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
- –£–∫–∞–∑—ã–≤–∞–π file_ref —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ù–ï–°–ö–û–õ–¨–ö–û —Ñ–∞–π–ª–æ–≤ –∏ –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π
- –ü—Ä–∏ —É–∫–∞–∑–∞–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ object_name –∏–ª–∏ file_id –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:**

–§–û–¢–û –ø–∏—Ç–æ–º—Ü–∞ (file_ref –ù–ï —É–∫–∞–∑—ã–≤–∞–µ–º –µ—Å–ª–∏ —Ñ–∞–π–ª –æ–¥–∏–Ω!):
‚Üí analyze_image(prompt="–û—Ü–µ–Ω–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∏—Ç–æ–º—Ü–∞, –æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞...")

–≠–¢–ò–ö–ï–¢–ö–ê –∫–æ—Ä–º–∞:
‚Üí ocr_image(mode="structured") –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ—Å—Ç–∞–≤–∞

–°–ü–†–ê–í–ö–ê –æ—Ç –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∞:
‚Üí ocr_image(mode="structured") –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∏–∞–≥–Ω–æ–∑–∞, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

–ì–û–õ–û–°–û–í–û–ï —Å–æ–æ–±—â–µ–Ω–∏–µ:
‚Üí transcribe_audio()

–í–ò–î–ï–û —Å –ø–∏—Ç–æ–º—Ü–µ–º:
‚Üí analyze_video(prompt="–û–ø–∏—à–∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, –æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞...", frame_count=10, transcribe=True)
  ‚Ä¢ frame_count - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ (–±–æ–ª—å—à–µ = –¥–µ—Ç–∞–ª—å–Ω–µ–µ, –Ω–æ –¥–æ–ª—å—à–µ). –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ (< 1 –º–∏–Ω) —Ö–≤–∞—Ç–∏—Ç 5-8, –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö (> 5 –º–∏–Ω) –∏—Å–ø–æ–ª—å–∑—É–π 10-15
  ‚Ä¢ transcribe - –∏–∑–≤–ª–µ—á—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ (True –µ—Å–ª–∏ –Ω–∞ –≤–∏–¥–µ–æ –µ—Å—Ç—å —Ä–µ—á—å/–∑–≤—É–∫)

**–í–∞–∂–Ω–æ:**
- –í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç JSON –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
- –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ - —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
- –ü—Ä–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö - —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∞
- –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ!"""
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])
            
            agent = create_tool_calling_agent(self.llm, self.tools, prompt)
            agent_executor = AgentExecutor(
                agent=agent,
                tools=self.tools,
                verbose=settings.DEBUG,
                handle_parsing_errors=True,
                max_iterations=5,
            )
            
            result = await agent_executor.ainvoke({"input": user_message})
            return result.get("output", '{"error": "No output"}')
            
        except Exception as e:
            logger.exception(f"MultimodalAgent error for user {user_id}")
            return json.dumps({"error": str(e)}, ensure_ascii=False)
        finally:
            if ctx_token is not None:
                _multimodal_context.reset(ctx_token)
            if minio_token is not None:
                _minio_service.reset(minio_token)
